{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a06e3f-3707-4ccb-82ad-96fd948c43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from models import get_model\n",
    "from trainers.metrics import get_metrics\n",
    "from trainers.optimizer import get_optimizer\n",
    "from trainers.criterion import get_criterion\n",
    "from data.dataloader import DataLoader\n",
    "from data.dataset import get_dataset\n",
    "from data.sampler import get_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd6e6bc-e84e-4953-85d9-01548d5ab844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment:\n",
      "  name: App\n",
      "data:\n",
      "  dataset:\n",
      "    name: cifar10\n",
      "    rootdir: /workspace/datasets\n",
      "    num_train_samples: 40000\n",
      "    in_channel: 3\n",
      "    num_class: 10\n",
      "    classes:\n",
      "    - plane\n",
      "    - car\n",
      "    - bird\n",
      "    - cat\n",
      "    - deer\n",
      "    - dog\n",
      "    - frog\n",
      "    - horse\n",
      "    - ship\n",
      "    - truck\n",
      "  sampler:\n",
      "    name: balanced_batch_sampler\n",
      "train:\n",
      "  batch_size: 10\n",
      "  epochs: 1\n",
      "  save_best_ckpt: true\n",
      "  num_workers: 2\n",
      "  ckpt_path: best_ckpt.pth\n",
      "  eval: false\n",
      "  optimizer:\n",
      "    name: adam\n",
      "    lr: 0.0001\n",
      "    decay: 0.0001\n",
      "  trainer:\n",
      "    name: default\n",
      "  criterion:\n",
      "    name: cross_entropy\n",
      "  metrics:\n",
      "    name: classification\n",
      "model:\n",
      "  name: simple_cnn\n",
      "  pretrained: false\n",
      "  initial_ckpt: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load setting\n",
    "cfg = OmegaConf.load('/workspace/app/app.yaml')\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a23ff74-4dac-49ba-9bc4-61ebaf7a2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = get_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0226a61-95cb-484e-a897-c72dbaf984a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics, optimizer and criterion\n",
    "metrics = get_metrics(cfg)\n",
    "optimizer = get_optimizer(cfg, model.network)\n",
    "criterion = get_criterion(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cc2feb-df39-420f-9a70-6a29e061e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "mode = \"trainval\"\n",
    "dataset = get_dataset(cfg, mode)\n",
    "sampler = get_sampler(cfg, mode, dataset)\n",
    "train_dataloader = DataLoader(cfg, dataset=dataset.train, sampler=sampler.train)\n",
    "val_dataloader = DataLoader(cfg, dataset=dataset.val, sampler=sampler.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7c9838-9f7d-4c5d-97f2-6e18a6c01416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecaluation function\n",
    "def eval(eval_dataloader: object = None, epoch: int = 0) -> float:\n",
    "        \"\"\"Evaluation\n",
    "\n",
    "        Evaluates model.\n",
    "\n",
    "        Args:\n",
    "            eval_dataloader: Dataloader.\n",
    "            epoch: Number of epoch.\n",
    "\n",
    "        Returns:\n",
    "            model_score: Indicator of the excellence of model. The higher the value, the better.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        model.network.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(eval_dataloader, ncols=100) as pbar:\n",
    "                for idx, (inputs, targets) in enumerate(pbar):\n",
    "                    inputs = inputs.to(model.device)\n",
    "                    targets = targets.to(model.device)\n",
    "\n",
    "                    outputs = model.network(inputs)\n",
    "\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    metrics.batch_update(outputs=outputs.cpu().detach().clone(),\n",
    "                                        targets=targets.cpu().detach().clone(),\n",
    "                                        loss=loss.item())\n",
    "\n",
    "                    pbar.set_description(f'eval epoch: {epoch}')\n",
    "        \n",
    "        metrics.epoch_update(epoch, mode='eval')\n",
    "\n",
    "        return metrics.model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6cf306-d9b0-4269-b436-2f7e8d5d69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model's check point\n",
    "def save_ckpt(epoch: int) -> None:\n",
    "        \"\"\"Save checkpoint\n",
    "\n",
    "        Saves checkpoint.\n",
    "\n",
    "        Args:\n",
    "            epoch: Number of epoch.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        ckpt_path = cfg.train.ckpt_path\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model.network,\n",
    "            'model_state_dict': model.network.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, ckpt_path)\n",
    "\n",
    "# Train function\n",
    "def train() -> None:\n",
    "        \"\"\"Train\n",
    "\n",
    "        Trains model.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        epochs = range(cfg.train.epochs)\n",
    "\n",
    "        for epoch in epochs:\n",
    "            print(f\"==================== Epoch: {epoch} ====================\")\n",
    "            print(f\"Train:\")\n",
    "            model.network.train()\n",
    "\n",
    "            with tqdm(train_dataloader, ncols=100) as pbar:\n",
    "                for idx, (inputs, targets) in enumerate(pbar):\n",
    "                    inputs = inputs.to(model.device)\n",
    "                    targets = targets.to(model.device)\n",
    "                    outputs = model.network(inputs)\n",
    "\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    metrics.batch_update(outputs=outputs.cpu().detach().clone(),\n",
    "                                            targets=targets.cpu().detach().clone(),\n",
    "                                            loss=loss.item())\n",
    "\n",
    "                    pbar.set_description(f'train epoch:{epoch}')\n",
    "\n",
    "            metrics.epoch_update(epoch, mode='train')\n",
    "            eval(eval_dataloader=val_dataloader, epoch=epoch)\n",
    "\n",
    "            if metrics.judge_update_ckpt:\n",
    "                save_ckpt(epoch=epoch)\n",
    "                print(\"Saved the check point.\")\n",
    "\n",
    "        print(\"Successfully trained the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32790df6-a88a-47f3-8c5a-57e286afcef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Epoch: 0 ====================\n",
      "Train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:0: 100%|████████████████████████████████████████████| 4000/4000 [00:47<00:00, 84.81it/s]\n",
      "eval epoch: 0: 100%|███████████████████████████████████████████| 1000/1000 [00:05<00:00, 189.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the check point.\n",
      "Successfully trained the model.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb11744-2cd4-46d2-b376-1ad4dcd5099b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval epoch: 0: 100%|███████████████████████████████████████████| 1000/1000 [00:05<00:00, 189.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43.540000915527344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "mode = \"test\"\n",
    "dataset = get_dataset(cfg, mode)\n",
    "sampler = get_sampler(cfg, mode, dataset)\n",
    "test_dataloader = DataLoader(cfg, dataset=dataset.test, sampler=sampler.test)\n",
    "eval(eval_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f7c9d-2c22-452d-b6b1-a4cc88977972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
